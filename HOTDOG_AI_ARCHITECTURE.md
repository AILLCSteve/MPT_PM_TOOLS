# HOTDOG AI Document Processing Architecture
**H**ierarchical **O**rchestrated **T**horough **D**ocument **O**versight & **G**uidance

**Date**: 2025-11-29
**Purpose**: Dynamic, user-centric AI architecture for exhaustive document analysis
**Focus**: PDF page accuracy, smart deduplication, flexible question sets, token efficiency

---

## Design Philosophy

**User-Centric Principles**:
1. **Purpose-Driven**: Every component serves the user's need for accurate bid spec analysis
2. **Flexible by Design**: Questions, sections, and experts adapt to each document
3. **Information Preservation**: Never lose details through deduplication or processing
4. **Citation Integrity**: PDF page numbers are first-class data, never optional metadata
5. **Exhaustive Coverage**: Process every page, answer every question, within token limits

**Not NEXUS**: This is a fresh design optimized for document analysis, not adapted from match prediction.

---

## Core Requirements

### 1. Perfect PDF Page Number Preservation
**Problem**: Currently broken - page numbers show in exports but not browser display
**Solution**: Page numbers are **mandatory metadata** attached to every answer at every stage

**Requirements**:
- âœ… Page numbers captured during extraction (Layer 0)
- âœ… Page numbers passed to AI in every prompt (Layer 3)
- âœ… Page numbers parsed from AI responses (Layer 3)
- âœ… Page numbers aggregated during deduplication (Layer 4)
- âœ… Page numbers displayed in browser AND exports (Layer 6)
- âœ… Page numbers validated at each layer (error if missing)

### 2. Smart Deduplication
**Problem**: 80% similarity can lose nuanced details
**Solution**: Semantic clustering with information merging

**Requirements**:
- âœ… Detect similar answers (embedding-based similarity)
- âœ… Merge complementary information (not replace)
- âœ… Preserve unique details from each occurrence
- âœ… Aggregate all page citations
- âœ… Track answer evolution across windows

**Example**:
- Window 1, Page 10: "Vinyl ester resin required"
- Window 5, Page 23: "Vinyl ester resin per ASTM F1216"
- Window 10, Page 41: "Resin shall cure at 180Â°F minimum"

**Bad Deduplication** (current): Keep only first answer, lose pages 23, 41
**Smart Deduplication** (HOTDOG): Merge into "Vinyl ester resin per ASTM F1216, shall cure at 180Â°F minimum <PDF pg 10, 23, 41>"

### 3. Exhaustive Document Coverage
**Problem**: Token limits can truncate analysis
**Solution**: Intelligent windowing with token budget management

**Requirements**:
- âœ… All pages processed (no skipping)
- âœ… All questions attempted (no omissions)
- âœ… Token budget tracked per window
- âœ… Dynamic prompt sizing based on remaining budget
- âœ… Overflow handling (split large sections if needed)

### 4. Dynamic Question Structure
**Problem**: Hardcoded 105 questions in 9 categories won't scale
**Solution**: Configuration-driven question sets

**Requirements**:
- âœ… Questions loaded from JSON/database
- âœ… Section headings configurable
- âœ… Number of questions variable (50-500+)
- âœ… Section groupings flexible
- âœ… Expert agents generated dynamically per section

**Example Configurations**:

**Config A - CIPP Bid Specs** (Current):
```json
{
  "sections": [
    {"name": "General Project Information", "questions": ["Q1", "Q2", ...]},
    {"name": "Materials & Equipment", "questions": ["Q28", "Q29", ...]},
    ...
  ]
}
```

**Config B - Construction Safety Audit**:
```json
{
  "sections": [
    {"name": "Safety Protocols", "questions": ["S1", "S2", ...]},
    {"name": "Hazard Identification", "questions": ["H1", "H2", ...]},
    ...
  ]
}
```

**Config C - Contract Review**:
```json
{
  "sections": [
    {"name": "Payment Terms", "questions": ["P1", "P2", ...]},
    {"name": "Dispute Resolution", "questions": ["D1", "D2", ...]},
    ...
  ]
}
```

### 5. Dynamic Expert Generation
**Problem**: Hardcoded agent prompts don't adapt to new question types
**Solution**: AI-generated expert personas from section metadata

**Requirements**:
- âœ… Section heading â†’ AI persona generation
- âœ… Persona includes: name, expertise, system prompt, strategy
- âœ… Persona optimized for question types in that section
- âœ… Persona caching (reuse for similar section names)
- âœ… Fallback generic persona if generation fails

**Process**:
```
Input: Section name "Materials & Equipment Specifications"
      â†“
AI Persona Generator Call:
  "Create an expert AI persona for analyzing construction bid
   specifications in the category: Materials & Equipment Specifications.

   Output format:
   - Expert Name: [descriptive name]
   - Specialization: [1-2 sentence description]
   - System Prompt: [detailed instructions for this expert]
   - Question Strategy: [how to approach questions in this domain]"
      â†“
Output: {
  "name": "Materials & Standards Compliance Specialist",
  "specialization": "Expert in construction materials specifications, ASTM standards, equipment requirements, and material testing protocols for infrastructure projects.",
  "system_prompt": "You are a materials engineering specialist with 20 years experience in CIPP and infrastructure rehabilitation. Extract factual information about: pipe materials, resin specifications, liner construction, curing methods, ASTM/AWWA standards, equipment requirements, and material testing. Always cite PDF page numbers as <PDF pg X>. Be precise with measurements, specifications, and standard references.",
  "strategy": "systematic_extraction"
}
```

---

## HOTDOG AI Architecture Overview

### Layer Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LAYER 0: Document Ingestion                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ PDF uploaded by user                                     â”‚  â”‚
â”‚  â”‚ â€¢ PyMuPDF extracts text with page numbers                 â”‚  â”‚
â”‚  â”‚ â€¢ Output: [(page_num, text), (page_num, text), ...]       â”‚  â”‚
â”‚  â”‚ â€¢ Metadata: {total_pages, file_name, upload_time}         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              LAYER 1: Dynamic Configuration Loader              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ Load question configuration (JSON/DB)                   â”‚  â”‚
â”‚  â”‚ â€¢ Parse sections and questions                            â”‚  â”‚
â”‚  â”‚ â€¢ Count: N sections, M total questions                    â”‚  â”‚
â”‚  â”‚ â€¢ Output: {sections[], questions[], section_map{}}        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           LAYER 2: Dynamic Expert Persona Generation            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ FOR EACH SECTION:                                          â”‚  â”‚
â”‚  â”‚   1. Check cache: Have we seen this section before?       â”‚  â”‚
â”‚  â”‚   2. If NO:                                                â”‚  â”‚
â”‚  â”‚      a. Call AI: "Generate expert persona for {section}"  â”‚  â”‚
â”‚  â”‚      b. Parse response â†’ {name, specialization, prompt}   â”‚  â”‚
â”‚  â”‚      c. Store in cache                                     â”‚  â”‚
â”‚  â”‚   3. If YES: Retrieve cached persona                      â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ â€¢ Output: {section_id â†’ expert_persona}                   â”‚  â”‚
â”‚  â”‚ â€¢ Example: "Materials" â†’ MaterialsSpecialist{...}         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         LAYER 3: Windowed Multi-Expert Processing (CORE)        â”‚
â”‚                                                                   â”‚
â”‚  FOR EACH 3-PAGE WINDOW:                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Window = Pages [P, P+1, P+2]                               â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ 1. Token Budget Check:                                     â”‚  â”‚
â”‚  â”‚    â€¢ Calculate tokens available                            â”‚  â”‚
â”‚  â”‚    â€¢ Adjust prompt length if needed                        â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ 2. Expert Routing:                                         â”‚  â”‚
â”‚  â”‚    â€¢ Group questions by section                            â”‚  â”‚
â”‚  â”‚    â€¢ Route each section to its expert                      â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ 3. Parallel Expert Calls:                                  â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚  â”‚
â”‚  â”‚    â”‚ Expert A     â”‚  â”‚ Expert B     â”‚  â”‚ Expert C     â”‚   â”‚  â”‚
â”‚  â”‚    â”‚ Questions    â”‚  â”‚ Questions    â”‚  â”‚ Questions    â”‚   â”‚  â”‚
â”‚  â”‚    â”‚ 1-15         â”‚  â”‚ 16-27        â”‚  â”‚ 28-45        â”‚   â”‚  â”‚
â”‚  â”‚    â”‚              â”‚  â”‚              â”‚  â”‚              â”‚   â”‚  â”‚
â”‚  â”‚    â”‚ â†“ AI Call   â”‚  â”‚ â†“ AI Call   â”‚  â”‚ â†“ AI Call   â”‚   â”‚  â”‚
â”‚  â”‚    â”‚              â”‚  â”‚              â”‚  â”‚              â”‚   â”‚  â”‚
â”‚  â”‚    â”‚ â†“ Answers   â”‚  â”‚ â†“ Answers   â”‚  â”‚ â†“ Answers   â”‚   â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ 4. Response Parsing:                                       â”‚  â”‚
â”‚  â”‚    â€¢ Extract answers                                       â”‚  â”‚
â”‚  â”‚    â€¢ Parse PDF page citations: <PDF pg X>                 â”‚  â”‚
â”‚  â”‚    â€¢ Calculate confidence scores                           â”‚  â”‚
â”‚  â”‚    â€¢ VALIDATE: Ensure page numbers present                â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ 5. Output per window:                                      â”‚  â”‚
â”‚  â”‚    {                                                        â”‚  â”‚
â”‚  â”‚      question_id â†’ {                                       â”‚  â”‚
â”‚  â”‚        answer: "text",                                     â”‚  â”‚
â”‚  â”‚        pages: [10, 11, 12],  â† MANDATORY                  â”‚  â”‚
â”‚  â”‚        confidence: 0.85,                                   â”‚  â”‚
â”‚  â”‚        expert: "MaterialsSpecialist",                      â”‚  â”‚
â”‚  â”‚        window: 5                                           â”‚  â”‚
â”‚  â”‚      }                                                      â”‚  â”‚
â”‚  â”‚    }                                                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          LAYER 4: Smart Accumulation & Deduplication            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ FOR EACH NEW ANSWER:                                       â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ 1. Semantic Similarity Check:                              â”‚  â”‚
â”‚  â”‚    â€¢ Compare with existing answers for this question      â”‚  â”‚
â”‚  â”‚    â€¢ Use embedding cosine similarity                       â”‚  â”‚
â”‚  â”‚    â€¢ Threshold: 0.80 (80% similar)                        â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ 2. IF SIMILAR ANSWER EXISTS:                              â”‚  â”‚
â”‚  â”‚    a. Information Merge:                                   â”‚  â”‚
â”‚  â”‚       â€¢ Combine unique details from both answers          â”‚  â”‚
â”‚  â”‚       â€¢ Keep more specific version as base                â”‚  â”‚
â”‚  â”‚       â€¢ Append complementary information                   â”‚  â”‚
â”‚  â”‚    b. Page Citation Aggregation:                          â”‚  â”‚
â”‚  â”‚       â€¢ Merge page lists: [10] + [23, 41] = [10, 23, 41] â”‚  â”‚
â”‚  â”‚       â€¢ Remove duplicates, sort ascending                  â”‚  â”‚
â”‚  â”‚    c. Confidence Update:                                   â”‚  â”‚
â”‚  â”‚       â€¢ Use highest confidence score                       â”‚  â”‚
â”‚  â”‚       â€¢ Or weighted average if both high                   â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ 3. IF NO SIMILAR ANSWER:                                  â”‚  â”‚
â”‚  â”‚    â€¢ APPEND as new answer entry                           â”‚  â”‚
â”‚  â”‚    â€¢ Rank by confidence for display                       â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ 4. Data Structure:                                         â”‚  â”‚
â”‚  â”‚    accumulated_answers = {                                 â”‚  â”‚
â”‚  â”‚      question_id: [                                        â”‚  â”‚
â”‚  â”‚        {                                                    â”‚  â”‚
â”‚  â”‚          text: "merged answer",                            â”‚  â”‚
â”‚  â”‚          pages: [10, 23, 41, 67],  â† ALL CITATIONS       â”‚  â”‚
â”‚  â”‚          confidence: 0.90,                                 â”‚  â”‚
â”‚  â”‚          expert: "MaterialsSpecialist",                    â”‚  â”‚
â”‚  â”‚          windows: [1, 5, 10, 15],                         â”‚  â”‚
â”‚  â”‚          created: timestamp,                               â”‚  â”‚
â”‚  â”‚          updated: timestamp                                â”‚  â”‚
â”‚  â”‚        },                                                   â”‚  â”‚
â”‚  â”‚        {...}  â† Additional distinct answers               â”‚  â”‚
â”‚  â”‚      ]                                                      â”‚  â”‚
â”‚  â”‚    }                                                        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             LAYER 5: Token Budget Manager (GUARDIAN)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Tracks and manages token usage to ensure exhaustive        â”‚  â”‚
â”‚  â”‚ coverage within OpenAI limits                              â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ BEFORE EACH WINDOW:                                        â”‚  â”‚
â”‚  â”‚   1. Calculate tokens used so far                          â”‚  â”‚
â”‚  â”‚   2. Calculate tokens remaining in budget                  â”‚  â”‚
â”‚  â”‚   3. Estimate tokens needed for this window                â”‚  â”‚
â”‚  â”‚   4. IF insufficient:                                      â”‚  â”‚
â”‚  â”‚      â€¢ Reduce context length (truncate text)              â”‚  â”‚
â”‚  â”‚      â€¢ Prioritize unanswered questions                     â”‚  â”‚
â”‚  â”‚      â€¢ Split window into smaller chunks                    â”‚  â”‚
â”‚  â”‚   5. ELSE: Proceed with full context                      â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ TRACKING:                                                   â”‚  â”‚
â”‚  â”‚   â€¢ Prompt tokens per window                               â”‚  â”‚
â”‚  â”‚   â€¢ Completion tokens per window                           â”‚  â”‚
â”‚  â”‚   â€¢ Total tokens per document                              â”‚  â”‚
â”‚  â”‚   â€¢ Questions answered vs remaining                        â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ STRATEGY:                                                   â”‚  â”‚
â”‚  â”‚   â€¢ Max tokens per request: 4000 prompt + 16000 completionâ”‚  â”‚
â”‚  â”‚   â€¢ Reserve 20% buffer for safety                          â”‚  â”‚
â”‚  â”‚   â€¢ Prioritize unanswered questions over refinement        â”‚  â”‚
â”‚  â”‚   â€¢ Log warnings if approaching limits                     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             LAYER 6: Output Compilation & Export                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 1. Unitary Log Table (Browser Display):                   â”‚  â”‚
â”‚  â”‚    â€¢ 1 row per question                                    â”‚  â”‚
â”‚  â”‚    â€¢ Show highest-confidence answer                        â”‚  â”‚
â”‚  â”‚    â€¢ Display all page citations: <PDF pg 10, 23, 41>     â”‚  â”‚
â”‚  â”‚    â€¢ Confidence badge: ğŸŸ¢ High / ğŸŸ¡ Medium / ğŸ”´ Low      â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ 2. Footnotes Section:                                      â”‚  â”‚
â”‚  â”‚    â€¢ Aggregate all unique footnotes                        â”‚  â”‚
â”‚  â”‚    â€¢ Include page citations for each                       â”‚  â”‚
â”‚  â”‚    â€¢ Deduplicate similar footnotes                         â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚ 3. Excel Export:                                           â”‚  â”‚
â”‚  â”‚    Sheet 1 - "Analysis Results":                           â”‚  â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚    â”‚ Question   â”‚ Answer  â”‚ Confidence â”‚ Pages â”‚ Expert â”‚ â”‚  â”‚
â”‚  â”‚    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚  â”‚
â”‚  â”‚    â”‚ Q1: Name?  â”‚ XYZ Projâ”‚ High (0.9) â”‚ 1,3,5 â”‚ GenPro â”‚ â”‚  â”‚
â”‚  â”‚    â”‚ Q28: Resin?â”‚ Vinyl...â”‚ High (0.85)â”‚10,23  â”‚ MatSpe â”‚ â”‚  â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚    Sheet 2 - "All Answers" (if multiple per question):    â”‚  â”‚
â”‚  â”‚    â€¢ Shows all answer variants                             â”‚  â”‚
â”‚  â”‚    â€¢ Sorted by confidence                                  â”‚  â”‚
â”‚  â”‚                                                             â”‚  â”‚
â”‚  â”‚    Sheet 3 - "Metadata":                                   â”‚  â”‚
â”‚  â”‚    â€¢ Document name, pages, processing time                 â”‚  â”‚
â”‚  â”‚    â€¢ Token usage statistics                                â”‚  â”‚
â”‚  â”‚    â€¢ Expert personas used                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Detailed Layer Specifications

### LAYER 0: Document Ingestion

**Purpose**: Extract text from PDF with perfect page number preservation

**Input**:
- PDF file uploaded by user
- File path: `/tmp/uploads/bid_spec_xyz.pdf`

**Process**:
```python
def extract_pdf_with_pages(pdf_path):
    """
    Extract text from PDF with page numbers as first-class data.

    Returns:
        List[PageData]: [{page_num: int, text: str, char_count: int}, ...]
    """
    pages = []
    doc = fitz.open(pdf_path)

    for page_num in range(len(doc)):
        page = doc[page_num]
        text = page.get_text()

        pages.append({
            'page_num': page_num + 1,  # 1-indexed for user display
            'text': text,
            'char_count': len(text),
            'has_content': len(text.strip()) > 50  # Detect blank pages
        })

    doc.close()

    metadata = {
        'total_pages': len(pages),
        'total_chars': sum(p['char_count'] for p in pages),
        'file_name': os.path.basename(pdf_path),
        'extraction_time': datetime.now()
    }

    return pages, metadata
```

**Output**:
```json
{
  "pages": [
    {"page_num": 1, "text": "BID SPECIFICATION...", "char_count": 3421},
    {"page_num": 2, "text": "Project Name: XYZ...", "char_count": 2890},
    ...
  ],
  "metadata": {
    "total_pages": 120,
    "total_chars": 245000,
    "file_name": "cipp_bid_2024.pdf"
  }
}
```

**Validation**:
- âœ… All pages have page_num field
- âœ… Page numbers are sequential (1, 2, 3, ...)
- âœ… No missing pages
- âœ… Text extracted for all pages (warn if blank)

---

### LAYER 1: Dynamic Configuration Loader

**Purpose**: Load question configuration dynamically (not hardcoded)

**Input Sources**:
1. **JSON File**: `configs/cipp_questions.json`
2. **Database**: `question_configs` table
3. **User Upload**: Custom question set

**Configuration Schema**:
```json
{
  "config_name": "CIPP Bid Specification Analysis",
  "version": "2.0",
  "sections": [
    {
      "section_id": "general_info",
      "section_name": "General Project Information",
      "description": "Project metadata, owner, contract details",
      "questions": [
        {
          "id": "Q1",
          "text": "What is the project name?",
          "required": true,
          "expected_answer_type": "string"
        },
        {
          "id": "Q2",
          "text": "Who is the project owner?",
          "required": true,
          "expected_answer_type": "string"
        },
        ...
      ]
    },
    {
      "section_id": "materials",
      "section_name": "Materials & Equipment Specifications",
      "description": "Pipe materials, resins, liners, ASTM standards",
      "questions": [
        {
          "id": "Q28",
          "text": "What resin type is required?",
          "required": true,
          "expected_answer_type": "technical_spec"
        },
        ...
      ]
    },
    ...
  ]
}
```

**Process**:
```python
class ConfigurationLoader:
    def load_config(self, source):
        """
        Load question configuration from JSON/DB/user upload.

        Returns:
            ParsedConfig: {
                sections: List[Section],
                questions: List[Question],
                section_map: Dict[section_id -> Section],
                question_map: Dict[question_id -> Question]
            }
        """
        # Load raw config
        if source.endswith('.json'):
            config_data = self._load_json(source)
        elif source == 'database':
            config_data = self._load_from_db()
        else:
            raise ValueError(f"Unknown config source: {source}")

        # Parse into structured objects
        sections = []
        questions = []

        for section_data in config_data['sections']:
            section = Section(
                id=section_data['section_id'],
                name=section_data['section_name'],
                description=section_data.get('description', ''),
                questions=[]
            )

            for q_data in section_data['questions']:
                question = Question(
                    id=q_data['id'],
                    text=q_data['text'],
                    section_id=section.id,
                    required=q_data.get('required', True),
                    expected_type=q_data.get('expected_answer_type', 'string')
                )
                section.questions.append(question)
                questions.append(question)

            sections.append(section)

        # Create lookup maps
        section_map = {s.id: s for s in sections}
        question_map = {q.id: q for q in questions}

        return ParsedConfig(
            sections=sections,
            questions=questions,
            section_map=section_map,
            question_map=question_map,
            metadata={'name': config_data['config_name'], 'version': config_data['version']}
        )
```

**Output**:
```python
ParsedConfig(
    sections=[
        Section(id='general_info', name='General Project Information', questions=[Q1, Q2, ...]),
        Section(id='materials', name='Materials & Equipment', questions=[Q28, Q29, ...]),
        ...
    ],
    total_questions=105,
    total_sections=9
)
```

**Validation**:
- âœ… All questions have unique IDs
- âœ… All sections have at least 1 question
- âœ… Question IDs referenced correctly
- âœ… No orphaned questions (every question belongs to a section)

---

### LAYER 2: Dynamic Expert Persona Generation

**Purpose**: Generate AI expert personas dynamically from section metadata

**Key Insight**: Instead of hardcoding expert prompts, use AI to create experts that match the section perfectly.

**Process Flow**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ INPUT: Section Object                                        â”‚
â”‚   â€¢ ID: "materials"                                          â”‚
â”‚   â€¢ Name: "Materials & Equipment Specifications"            â”‚
â”‚   â€¢ Description: "Pipe materials, resins, ASTM standards"   â”‚
â”‚   â€¢ Questions: [Q28, Q29, Q30, ...]                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Check Expert Cache                                   â”‚
â”‚   cache_key = hash(section_name)                            â”‚
â”‚   if cache_key in expert_cache:                             â”‚
â”‚       return cached_expert  â† REUSE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“ (cache miss)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Generate Expert Persona via AI                      â”‚
â”‚                                                               â”‚
â”‚   AI Prompt:                                                 â”‚
â”‚   """                                                         â”‚
â”‚   You are an expert AI architect. Design a specialized      â”‚
â”‚   AI persona for document analysis.                         â”‚
â”‚                                                               â”‚
â”‚   Section: Materials & Equipment Specifications             â”‚
â”‚   Description: Pipe materials, resins, liners, ASTM         â”‚
â”‚   Sample Questions:                                          â”‚
â”‚   - What resin type is required?                            â”‚
â”‚   - What ASTM standards apply?                              â”‚
â”‚   - What liner thickness is specified?                      â”‚
â”‚                                                               â”‚
â”‚   Generate:                                                  â”‚
â”‚   1. Expert Name: [creative, descriptive name]              â”‚
â”‚   2. Specialization: [2-3 sentences of expertise]          â”‚
â”‚   3. System Prompt: [detailed instructions for this expert] â”‚
â”‚   4. Citation Strategy: [how to extract page numbers]       â”‚
â”‚   5. Answer Format: [structure of responses]                â”‚
â”‚                                                               â”‚
â”‚   Output as JSON.                                            â”‚
â”‚   """                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Parse AI Response                                   â”‚
â”‚                                                               â”‚
â”‚   Response:                                                  â”‚
â”‚   {                                                           â”‚
â”‚     "expert_name": "CIPP Materials & Standards Specialist", â”‚
â”‚     "specialization": "Expert in polymer resin chemistry,   â”‚
â”‚       ASTM/AWWA standards for pipe rehabilitation, felt     â”‚
â”‚       liner construction, and curing methodologies. 20+     â”‚
â”‚       years in infrastructure materials engineering.",      â”‚
â”‚     "system_prompt": "You are a materials engineering       â”‚
â”‚       specialist with deep expertise in CIPP technology.    â”‚
â”‚       Extract factual information about:\n                  â”‚
â”‚       - Resin types (polyester, vinyl ester, epoxy)\n      â”‚
â”‚       - ASTM standards (F1216, F1743, D5813, etc.)\n       â”‚
â”‚       - Liner specifications (thickness, felt type)\n       â”‚
â”‚       - Curing methods (steam, hot water, UV, ambient)\n   â”‚
â”‚       - Equipment requirements\n                            â”‚
â”‚       Always cite PDF page numbers: <PDF pg X>\n           â”‚
â”‚       Be precise with measurements and standard numbers.",  â”‚
â”‚     "citation_strategy": "Extract page numbers from source  â”‚
â”‚       text. Include in every answer as: <PDF pg X>",       â”‚
â”‚     "answer_format": "Direct, factual answer with specific â”‚
â”‚       measurements, standards, or requirements. Cite pages."â”‚
â”‚   }                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Create Expert Object & Cache                        â”‚
â”‚                                                               â”‚
â”‚   expert = ExpertPersona(                                    â”‚
â”‚       id=generate_id(section.id + "_expert"),               â”‚
â”‚       name="CIPP Materials & Standards Specialist",         â”‚
â”‚       section_id=section.id,                                â”‚
â”‚       system_prompt=parsed['system_prompt'],                â”‚
â”‚       specialization=parsed['specialization'],              â”‚
â”‚       citation_strategy=parsed['citation_strategy'],        â”‚
â”‚       answer_format=parsed['answer_format'],                â”‚
â”‚       created_at=now(),                                      â”‚
â”‚       cache_key=hash(section.name)                          â”‚
â”‚   )                                                           â”‚
â”‚                                                               â”‚
â”‚   expert_cache[cache_key] = expert  â† STORE FOR REUSE      â”‚
â”‚                                                               â”‚
â”‚   return expert                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Implementation**:

```python
class ExpertPersonaGenerator:
    def __init__(self, openai_client, cache_store):
        self.client = openai_client
        self.cache = cache_store  # Redis or in-memory dict

    def generate_expert(self, section: Section) -> ExpertPersona:
        """
        Generate or retrieve cached expert persona for a section.

        Args:
            section: Section object with name, description, questions

        Returns:
            ExpertPersona: Complete expert configuration
        """
        # Check cache first
        cache_key = self._make_cache_key(section.name)
        cached = self.cache.get(cache_key)
        if cached:
            logger.info(f"Expert cache HIT for section: {section.name}")
            return ExpertPersona.from_json(cached)

        logger.info(f"Expert cache MISS - generating for: {section.name}")

        # Build generation prompt
        sample_questions = '\n'.join([f"- {q.text}" for q in section.questions[:5]])

        prompt = f"""You are an expert AI architect designing specialized document analysis personas.

Create an expert AI persona for analyzing construction/engineering bid specifications.

**Section Details:**
- Name: {section.name}
- Description: {section.description}
- Sample Questions:
{sample_questions}

**Generate the following (output as JSON):**

1. **expert_name**: A creative, descriptive name for this expert (e.g., "CIPP Materials & Standards Compliance Specialist")

2. **specialization**: 2-3 sentences describing this expert's domain knowledge and experience

3. **system_prompt**: Detailed instructions for this expert including:
   - Areas of expertise
   - Types of information to extract
   - Required citation format: <PDF pg X>
   - Precision requirements (measurements, standards, etc.)
   - Answer style (factual, concise, technical)

4. **citation_strategy**: How this expert should extract and include PDF page numbers

5. **answer_format**: Structure and style of answers this expert should produce

**CRITICAL**: The expert MUST always include PDF page citations in format: <PDF pg X>

Output only valid JSON, no markdown formatting."""

        # Call AI to generate expert
        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are an expert AI architect."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,  # Some creativity for persona generation
            response_format={"type": "json_object"}
        )

        # Parse response
        expert_data = json.loads(response.choices[0].message.content)

        # Validate required fields
        required_fields = ['expert_name', 'specialization', 'system_prompt',
                          'citation_strategy', 'answer_format']
        for field in required_fields:
            if field not in expert_data:
                raise ValueError(f"Expert generation missing field: {field}")

        # Create expert object
        expert = ExpertPersona(
            id=f"{section.id}_expert",
            name=expert_data['expert_name'],
            section_id=section.id,
            section_name=section.name,
            system_prompt=expert_data['system_prompt'],
            specialization=expert_data['specialization'],
            citation_strategy=expert_data['citation_strategy'],
            answer_format=expert_data['answer_format'],
            created_at=datetime.now()
        )

        # Cache for future use
        self.cache.set(cache_key, expert.to_json(), ttl=86400 * 30)  # 30 days

        logger.info(f"Generated expert: {expert.name}")
        return expert

    def _make_cache_key(self, section_name: str) -> str:
        """Generate consistent cache key from section name."""
        normalized = section_name.lower().strip()
        return f"expert:{hashlib.sha256(normalized.encode()).hexdigest()[:16]}"
```

**Example Output**:

For section "Safety & Environmental Compliance":

```json
{
  "expert_name": "Safety & Environmental Compliance Officer",
  "specialization": "Expert in OSHA regulations, environmental permitting (NPDES, air quality), confined space procedures, traffic control planning, and emergency response protocols for construction projects. Certified in hazardous materials management and municipal infrastructure safety standards.",
  "system_prompt": "You are a safety and environmental compliance specialist with expertise in construction site safety, environmental regulations, and permit requirements. Extract information about:\n- OSHA safety requirements and procedures\n- Environmental permits (NPDES, stormwater, air quality)\n- Confined space entry protocols\n- Traffic control and public safety measures\n- Hazardous materials handling\n- Emergency response plans\n- Safety training and certification requirements\n\nAlways cite PDF page numbers as: <PDF pg X>\nBe specific about regulatory requirements, permit types, and safety procedures.",
  "citation_strategy": "Extract page numbers from the source document and include them in every answer using the format <PDF pg X>. If information spans multiple pages, list all relevant pages: <PDF pg 12, 15, 18>",
  "answer_format": "Factual, regulatory-focused answers. Include specific requirement names, permit types, and procedural steps. Cite all relevant PDF pages."
}
```

**Fallback Strategy**:

If expert generation fails (API error, timeout, invalid response):

```python
def create_generic_expert(section: Section) -> ExpertPersona:
    """Fallback generic expert if generation fails."""
    return ExpertPersona(
        id=f"{section.id}_expert",
        name=f"{section.name} Specialist",
        section_id=section.id,
        system_prompt=f"""You are a document analysis expert specializing in {section.name}.

Extract factual information from construction bid specifications related to this category.

Always cite PDF page numbers in your answers using the format: <PDF pg X>

Be precise, factual, and thorough in your responses.""",
        specialization=f"Expert in {section.name} for construction document analysis.",
        citation_strategy="Include <PDF pg X> in all answers",
        answer_format="Direct, factual answers with page citations"
    )
```

**Benefits**:
- âœ… Adapts to ANY section name (not hardcoded)
- âœ… Optimizes expert for specific question types
- âœ… Reuses cached experts (cost efficient)
- âœ… Falls back gracefully if generation fails
- âœ… Enforces PDF citation requirement in system prompt

---

### LAYER 3: Windowed Multi-Expert Processing (CORE ENGINE)

**Purpose**: Process PDF in 3-page windows with parallel expert calls and mandatory page citation

**This is the heart of HOTDOG AI where actual document analysis happens.**

**Window Processing Flow**:

```
FOR each 3-page window in document:
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WINDOW n: Pages [P, P+1, P+2]                                â”‚
â”‚                                                               â”‚
â”‚ Example: Window 5 = Pages [13, 14, 15]                      â”‚
â”‚ Combined text: ~6000 characters                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Token Budget Check (Layer 5 Guardian)               â”‚
â”‚   â€¢ Tokens used so far: 45,000                              â”‚
â”‚   â€¢ Tokens remaining: 35,000                                 â”‚
â”‚   â€¢ Estimated for this window: 8,000                         â”‚
â”‚   â€¢ Status: âœ… PROCEED                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Route Questions to Experts                          â”‚
â”‚                                                               â”‚
â”‚   All 105 questions grouped by section:                     â”‚
â”‚   â€¢ General Info (Q1-Q15) â†’ GeneralProjectExpert            â”‚
â”‚   â€¢ Materials (Q28-Q45) â†’ MaterialsSpecialist               â”‚
â”‚   â€¢ Safety (Q70-Q80) â†’ SafetyComplianceOfficer              â”‚
â”‚   ... (all 9 sections)                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Build Expert Prompts                                â”‚
â”‚                                                               â”‚
â”‚   For MaterialsSpecialist:                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚ SYSTEM: {expert.system_prompt}                        â”‚ â”‚
â”‚   â”‚                                                         â”‚ â”‚
â”‚   â”‚ USER:                                                   â”‚ â”‚
â”‚   â”‚ You are analyzing pages 13-15 of a bid specification. â”‚ â”‚
â”‚   â”‚                                                         â”‚ â”‚
â”‚   â”‚ **CRITICAL**: For every answer you provide, you MUST  â”‚ â”‚
â”‚   â”‚ include PDF page citations in this exact format:      â”‚ â”‚
â”‚   â”‚ <PDF pg 13> or <PDF pg 13, 14> for multi-page info.  â”‚ â”‚
â”‚   â”‚                                                         â”‚ â”‚
â”‚   â”‚ Current pages being analyzed: 13, 14, 15              â”‚ â”‚
â”‚   â”‚                                                         â”‚ â”‚
â”‚   â”‚ Context (from pages 13-15):                            â”‚ â”‚
â”‚   â”‚ [TEXT FROM PAGES 13-15]                                â”‚ â”‚
â”‚   â”‚                                                         â”‚ â”‚
â”‚   â”‚ Questions:                                              â”‚ â”‚
â”‚   â”‚ Q28. What resin type is required?                      â”‚ â”‚
â”‚   â”‚ Q29. What ASTM standards apply to materials?          â”‚ â”‚
â”‚   â”‚ Q30. What liner thickness is specified?               â”‚ â”‚
â”‚   â”‚ ...                                                     â”‚ â”‚
â”‚   â”‚                                                         â”‚ â”‚
â”‚   â”‚ Output format (JSON):                                  â”‚ â”‚
â”‚   â”‚ {                                                       â”‚ â”‚
â”‚   â”‚   "Q28": {                                             â”‚ â”‚
â”‚   â”‚     "answer": "Your answer here <PDF pg X>",          â”‚ â”‚
â”‚   â”‚     "confidence": 0.85,                                â”‚ â”‚
â”‚   â”‚     "pages": [13, 14]                                 â”‚ â”‚
â”‚   â”‚   },                                                    â”‚ â”‚
â”‚   â”‚   ...                                                   â”‚ â”‚
â”‚   â”‚ }                                                       â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Parallel Expert API Calls                           â”‚
â”‚                                                               â”‚
â”‚   async def process_all_experts():                          â”‚
â”‚       tasks = []                                             â”‚
â”‚       for expert in active_experts:                         â”‚
â”‚           task = call_expert_async(expert, window_context)  â”‚
â”‚           tasks.append(task)                                 â”‚
â”‚       results = await asyncio.gather(*tasks)                â”‚
â”‚       return results                                         â”‚
â”‚                                                               â”‚
â”‚   Executes 9-10 AI calls IN PARALLEL                        â”‚
â”‚   Typical latency: 3-5 seconds (vs 30s sequential)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: Parse Expert Responses                              â”‚
â”‚                                                               â”‚
â”‚   MaterialsSpecialist response:                             â”‚
â”‚   {                                                           â”‚
â”‚     "Q28": {                                                 â”‚
â”‚       "answer": "Vinyl ester resin per ASTM F1216 <PDF pg 13>",â”‚
â”‚       "confidence": 0.90,                                    â”‚
â”‚       "pages": [13]                                         â”‚
â”‚     },                                                        â”‚
â”‚     "Q29": {                                                 â”‚
â”‚       "answer": "ASTM F1216, F1743, D5813 <PDF pg 13, 14>",â”‚
â”‚       "confidence": 0.95,                                    â”‚
â”‚       "pages": [13, 14]                                     â”‚
â”‚     },                                                        â”‚
â”‚     ...                                                       â”‚
â”‚   }                                                           â”‚
â”‚                                                               â”‚
â”‚   VALIDATION for each answer:                                â”‚
â”‚   âœ… Has "answer" field                                      â”‚
â”‚   âœ… Has "pages" array with at least one page number        â”‚
â”‚   âœ… Page numbers are within current window [13,14,15]      â”‚
â”‚   âœ… Answer text contains "<PDF pg X>" citation             â”‚
â”‚   âŒ REJECT if missing pages or citation                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: Confidence Scoring                                  â”‚
â”‚                                                               â”‚
â”‚   For each answer, calculate confidence if not provided:    â”‚
â”‚   - Length & specificity (longer, detailed = higher)        â”‚
â”‚   - Presence of concrete facts (numbers, standards, dates)  â”‚
â”‚   - Hedge words ("may", "unclear") â†’ lower                  â”‚
â”‚   - Definitive language ("shall", "required") â†’ higher      â”‚
â”‚                                                               â”‚
â”‚   Score range: 0.0 (no confidence) to 1.0 (certain)        â”‚
â”‚   Classification: High â‰¥0.7, Medium 0.4-0.7, Low <0.4       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: Window Results                                       â”‚
â”‚   {                                                           â”‚
â”‚     window_num: 5,                                           â”‚
â”‚     pages: [13, 14, 15],                                    â”‚
â”‚     answers: {                                               â”‚
â”‚       "Q28": {                                              â”‚
â”‚         answer: "Vinyl ester resin per ASTM F1216 <PDF pg 13>",â”‚
â”‚         pages: [13],                                        â”‚
â”‚         confidence: 0.90,                                    â”‚
â”‚         expert: "MaterialsSpecialist",                      â”‚
â”‚         window: 5                                            â”‚
â”‚       },                                                      â”‚
â”‚       "Q29": {...},                                          â”‚
â”‚       ... (all answers from all experts)                    â”‚
â”‚     },                                                        â”‚
â”‚     tokens_used: 7842,                                       â”‚
â”‚     processing_time: 4.2s                                    â”‚
â”‚   }                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†“
  Pass to Layer 4 (Accumulation)
```

**Critical Implementation Details**:

**1. Mandatory Page Citation Enforcement**:

```python
def validate_answer(answer_obj, window_pages):
    """Strict validation of answer structure and page citations."""

    # Check required fields
    if 'answer' not in answer_obj:
        raise ValidationError("Missing 'answer' field")
    if 'pages' not in answer_obj:
        raise ValidationError("Missing 'pages' field")

    # Validate pages array
    if not isinstance(answer_obj['pages'], list):
        raise ValidationError("'pages' must be an array")
    if len(answer_obj['pages']) == 0:
        raise ValidationError("'pages' array is empty - PDF citations required")

    # Validate page numbers are in current window
    for page in answer_obj['pages']:
        if page not in window_pages:
            logger.warning(f"Page {page} not in current window {window_pages}")
            # Don't reject, but log for investigation

    # Validate answer text contains citation marker
    if '<PDF pg' not in answer_obj['answer']:
        logger.warning(f"Answer missing <PDF pg> citation marker: {answer_obj['answer'][:100]}")
        # Inject citation if missing
        answer_obj['answer'] = f"{answer_obj['answer']} <PDF pg {', '.join(map(str, answer_obj['pages']))}>"

    return True
```

**2. Parallel Expert Execution**:

```python
import asyncio
from typing import List, Dict

class MultiExpertProcessor:
    def __init__(self, experts: List[ExpertPersona], openai_client):
        self.experts = experts
        self.client = openai_client

    async def process_window(self, window_data, questions_by_section):
        """
        Process all experts in parallel for this window.

        Args:
            window_data: {pages: [13,14,15], text: "..."}
            questions_by_section: {section_id: [Question, ...]}

        Returns:
            Dict[question_id -> answer_data]
        """
        # Create tasks for each expert
        tasks = []
        for expert in self.experts:
            section_questions = questions_by_section.get(expert.section_id, [])
            if section_questions:
                task = self._call_expert_async(expert, window_data, section_questions)
                tasks.append(task)

        # Execute all tasks in parallel
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # Merge results from all experts
        all_answers = {}
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"Expert call failed: {result}")
                continue
            all_answers.update(result)

        return all_answers

    async def _call_expert_async(self, expert, window_data, questions):
        """Call single expert asynchronously."""
        prompt = self._build_expert_prompt(expert, window_data, questions)

        try:
            response = await self.client.chat.completions.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": expert.system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )

            answers = json.loads(response.choices[0].message.content)

            # Validate each answer
            for q_id, answer_data in answers.items():
                self._validate_answer(answer_data, window_data['pages'])

            return answers

        except Exception as e:
            logger.error(f"Expert {expert.name} failed: {e}")
            return {}

    def _build_expert_prompt(self, expert, window_data, questions):
        """Build comprehensive prompt for expert."""
        pages_str = ', '.join(map(str, window_data['pages']))

        questions_text = '\n'.join([f"{q.id}. {q.text}" for q in questions])

        prompt = f"""You are analyzing pages {pages_str} of a bid specification document.

**CRITICAL REQUIREMENT**: For EVERY answer, you MUST include PDF page citations.
Format: <PDF pg X> or <PDF pg X, Y> for multi-page information.

Current pages: {pages_str}

**Document Context (pages {pages_str})**:
{window_data['text']}

**Questions to answer**:
{questions_text}

**Output Requirements**:
1. Answer every question based on information in these pages
2. If no information found, state "Not specified in pages {pages_str}" <PDF pg {pages_str}>
3. Include page citations in EVERY answer
4. Provide confidence score (0.0-1.0) for each answer
5. List relevant page numbers in "pages" array

**Output format (JSON)**:
{{
  "Q1": {{
    "answer": "Your answer with citation <PDF pg X>",
    "confidence": 0.85,
    "pages": [13, 14]
  }},
  ...
}}"""

        return prompt
```

**Output Example** from Window 5 (pages 13-15):

```json
{
  "window_num": 5,
  "pages": [13, 14, 15],
  "answers": {
    "Q1": {
      "answer": "XYZ Sewer Rehabilitation Project <PDF pg 13>",
      "pages": [13],
      "confidence": 0.95,
      "expert": "GeneralProjectExpert",
      "window": 5
    },
    "Q28": {
      "answer": "Vinyl ester resin conforming to ASTM F1216 <PDF pg 13, 14>",
      "pages": [13, 14],
      "confidence": 0.92,
      "expert": "MaterialsSpecialist",
      "window": 5
    },
    "Q29": {
      "answer": "ASTM F1216, F1743, D5813 for resin and liner specifications <PDF pg 14>",
      "pages": [14],
      "confidence": 0.90,
      "expert": "MaterialsSpecialist",
      "window": 5
    },
    "Q70": {
      "answer": "Confined space entry requires OSHA 1910.146 compliance, atmospheric testing, and rescue plan <PDF pg 15>",
      "pages": [15],
      "confidence": 0.88,
      "expert": "SafetyComplianceOfficer",
      "window": 5
    }
  },
  "tokens_used": 8234,
  "processing_time_seconds": 4.3,
  "expert_count": 9
}
```

---

### LAYER 4: Smart Accumulation & Deduplication

**Purpose**: Merge answers from multiple windows intelligently without losing information

**Key Challenge**: Same question asked across 33 windows = 33 potential answers per question. How to consolidate without losing details?

**Solution**: Semantic clustering + information merging + citation aggregation

**Process Flow**:

```
New Answer from Window 5:
  Q28: "Vinyl ester resin per ASTM F1216 <PDF pg 13, 14>"
  pages: [13, 14]
  confidence: 0.92
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 1: Check Existing Answers for Q28                      â”‚
â”‚                                                               â”‚
â”‚   accumulated_answers[Q28] = [                               â”‚
â”‚     {                                                         â”‚
â”‚       answer: "Vinyl ester resin required <PDF pg 3>",      â”‚
â”‚       pages: [3],                                            â”‚
â”‚       confidence: 0.75,                                      â”‚
â”‚       windows: [1]                                           â”‚
â”‚     }                                                         â”‚
â”‚   ]                                                           â”‚
â”‚                                                               â”‚
â”‚   Found 1 existing answer                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 2: Calculate Semantic Similarity                       â”‚
â”‚                                                               â”‚
â”‚   existing: "Vinyl ester resin required"                    â”‚
â”‚   new:      "Vinyl ester resin per ASTM F1216"             â”‚
â”‚                                                               â”‚
â”‚   Method: Cosine similarity on embeddings                    â”‚
â”‚   Similarity score: 0.87 (87% similar)                      â”‚
â”‚   Threshold: 0.80                                            â”‚
â”‚   Result: SIMILAR â†’ Merge information                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 3: Information Merging Strategy                        â”‚
â”‚                                                               â”‚
â”‚   Identify unique information in each:                      â”‚
â”‚   - Existing: "required" (vague)                            â”‚
â”‚   - New: "per ASTM F1216" (specific standard reference)     â”‚
â”‚                                                               â”‚
â”‚   Merge strategy: Keep more specific version, add details   â”‚
â”‚                                                               â”‚
â”‚   Merged answer:                                             â”‚
â”‚   "Vinyl ester resin per ASTM F1216 required <PDF pg 3, 13, 14>"â”‚
â”‚                                                               â”‚
â”‚   Why: New answer is more specific (includes standard),     â”‚
â”‚         but preserve "required" wording from original        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 4: Page Citation Aggregation                           â”‚
â”‚                                                               â”‚
â”‚   Existing pages: [3]                                        â”‚
â”‚   New pages: [13, 14]                                        â”‚
â”‚                                                               â”‚
â”‚   Merge: [3] + [13, 14] = [3, 13, 14]                      â”‚
â”‚   Remove duplicates: N/A                                     â”‚
â”‚   Sort ascending: [3, 13, 14] âœ…                            â”‚
â”‚                                                               â”‚
â”‚   Updated answer:                                            â”‚
â”‚   "Vinyl ester resin per ASTM F1216 required <PDF pg 3, 13, 14>"â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 5: Confidence Update                                   â”‚
â”‚                                                               â”‚
â”‚   Existing confidence: 0.75                                  â”‚
â”‚   New confidence: 0.92                                       â”‚
â”‚                                                               â”‚
â”‚   Strategy: Use HIGHEST confidence (more specific answer)   â”‚
â”‚   Updated confidence: 0.92                                   â”‚
â”‚                                                               â”‚
â”‚   Rationale: The answer with standard reference (F1216)     â”‚
â”‚   is more authoritative than vague "required"               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STEP 6: Update Accumulated Answer                           â”‚
â”‚                                                               â”‚
â”‚   accumulated_answers[Q28] = [                               â”‚
â”‚     {                                                         â”‚
â”‚       answer: "Vinyl ester resin per ASTM F1216 required <PDF pg 3, 13, 14>",â”‚
â”‚       pages: [3, 13, 14],                                   â”‚
â”‚       confidence: 0.92,                                      â”‚
â”‚       windows: [1, 5],                                       â”‚
â”‚       expert: "MaterialsSpecialist",                        â”‚
â”‚       created_window: 1,                                     â”‚
â”‚       last_updated_window: 5,                               â”‚
â”‚       merge_count: 1                                         â”‚
â”‚     }                                                         â”‚
â”‚   ]                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Edge Case: Complementary Information (NOT Duplication)**

```
Window 1, Page 3:
  Q28: "Vinyl ester resin required"

Window 5, Pages 13-14:
  Q28: "Vinyl ester resin per ASTM F1216"

Window 10, Page 41:
  Q28: "Resin shall cure at minimum 180Â°F"

Window 15, Page 67:
  Q28: "Minimum wall thickness after curing: 6mm"
```

**Similarity Analysis**:
- Answer 1 vs Answer 2: 87% similar â†’ MERGE
- Merged 1+2 vs Answer 3: 45% similar â†’ SEPARATE (different aspect: curing temp)
- Merged 1+2 vs Answer 4: 40% similar â†’ SEPARATE (different aspect: thickness)
- Answer 3 vs Answer 4: 30% similar â†’ SEPARATE (both distinct)

**Final Accumulated State for Q28**:

```python
accumulated_answers["Q28"] = [
    {
        "answer": "Vinyl ester resin per ASTM F1216 required <PDF pg 3, 13, 14>",
        "pages": [3, 13, 14],
        "confidence": 0.92,
        "type": "material_specification",
        "windows": [1, 5]
    },
    {
        "answer": "Resin shall cure at minimum 180Â°F <PDF pg 41>",
        "pages": [41],
        "confidence": 0.85,
        "type": "curing_requirement",
        "windows": [10]
    },
    {
        "answer": "Minimum wall thickness after curing: 6mm <PDF pg 67>",
        "pages": [67],
        "confidence": 0.88,
        "type": "dimensional_requirement",
        "windows": [15]
    }
]
```

**Display Strategy**:
- **Browser**: Show highest-confidence answer (first one), with "+ 2 more details" link
- **Export**: Include ALL three answers in separate rows

**Implementation**:

```python
class SmartAccumulator:
    def __init__(self, embedding_model):
        self.answers = {}  # {question_id: [AnswerEntry, ...]}
        self.embedder = embedding_model
        self.similarity_threshold = 0.80

    def accumulate(self, question_id, new_answer_data):
        """
        Intelligently accumulate new answer with existing answers.

        Args:
            question_id: str
            new_answer_data: {
                answer: str,
                pages: List[int],
                confidence: float,
                expert: str,
                window: int
            }
        """
        # Initialize if first answer for this question
        if question_id not in self.answers:
            self.answers[question_id] = []
            self.answers[question_id].append(new_answer_data)
            logger.info(f"{question_id}: First answer added")
            return

        # Calculate similarity with all existing answers
        new_embedding = self.embedder.embed(new_answer_data['answer'])

        best_match = None
        best_similarity = 0.0

        for existing in self.answers[question_id]:
            existing_embedding = self.embedder.embed(existing['answer'])
            similarity = cosine_similarity(new_embedding, existing_embedding)

            if similarity > best_similarity:
                best_similarity = similarity
                best_match = existing

        # Decision: Merge or Append?
        if best_similarity >= self.similarity_threshold:
            # MERGE: Similar enough to be same information
            logger.info(f"{question_id}: Merging (similarity: {best_similarity:.2f})")
            self._merge_answers(best_match, new_answer_data)
        else:
            # APPEND: Distinct information
            logger.info(f"{question_id}: Appending as new variant (similarity: {best_similarity:.2f})")
            self.answers[question_id].append(new_answer_data)
            # Sort by confidence (highest first)
            self.answers[question_id].sort(key=lambda x: x['confidence'], reverse=True)

    def _merge_answers(self, existing, new):
        """
        Merge two similar answers, preserving all information and citations.

        Strategy:
        1. Use more specific/detailed answer as base
        2. Add unique details from other answer
        3. Aggregate all page citations
        4. Use highest confidence score
        """
        # Determine which answer is more specific
        if len(new['answer']) > len(existing['answer']) * 1.2:
            # New answer significantly longer/more detailed
            base_answer = new['answer']
            supplemental = existing['answer']
        else:
            # Existing answer is base
            base_answer = existing['answer']
            supplemental = new['answer']

        # Extract unique information from supplemental
        # (simplified: in production, use NLP to extract unique clauses)
        unique_info = self._extract_unique_info(base_answer, supplemental)

        # Merge answer text
        if unique_info:
            merged_text = f"{base_answer}. {unique_info}"
        else:
            merged_text = base_answer

        # Aggregate page citations
        all_pages = sorted(set(existing['pages'] + new['pages']))

        # Update citation markers in text
        merged_text = self._update_citations(merged_text, all_pages)

        # Update existing answer in place
        existing['answer'] = merged_text
        existing['pages'] = all_pages
        existing['confidence'] = max(existing['confidence'], new['confidence'])
        existing['windows'] = existing.get('windows', [existing.get('window')]) + [new['window']]
        existing['merge_count'] = existing.get('merge_count', 0) + 1
        existing['last_updated'] = datetime.now()

    def _extract_unique_info(self, base, supplemental):
        """Extract information in supplemental that's not in base."""
        # Simplified version: check for unique phrases
        base_words = set(base.lower().split())
        supp_words = set(supplemental.lower().split())
        unique_words = supp_words - base_words

        if len(unique_words) > 3:  # Has meaningful unique content
            # Return phrases from supplemental containing unique words
            # (production: use NLP chunking)
            return supplemental
        return ""

    def _update_citations(self, text, pages):
        """Update <PDF pg X> markers with all relevant pages."""
        # Remove old citation markers
        text = re.sub(r'<PDF pg [0-9, ]+>', '', text)

        # Add new aggregated citation
        pages_str = ', '.join(map(str, pages))
        return f"{text.strip()} <PDF pg {pages_str}>"

    def get_display_answer(self, question_id):
        """Get primary answer for browser display (highest confidence)."""
        if question_id not in self.answers or not self.answers[question_id]:
            return None

        # Already sorted by confidence
        return self.answers[question_id][0]

    def get_all_answers(self, question_id):
        """Get all answer variants for export."""
        return self.answers.get(question_id, [])
```

**Benefits of Smart Accumulation**:
- âœ… Never loses information (everything preserved or merged)
- âœ… Aggregates all page citations (perfect PDF references)
- âœ… Prioritizes more specific/detailed answers
- âœ… Handles complementary information correctly (separate answers)
- âœ… Confidence-weighted ranking for display

---

### LAYER 5: Token Budget Manager (Guardian)

**Purpose**: Ensure exhaustive coverage within OpenAI token limits

**Challenge**:
- 100-page PDF Ã— 33 windows Ã— 105 questions = massive token usage
- OpenAI limit: 16,384 tokens output (gpt-4), 4,096 input (varies by model)
- Must process ALL pages and ALL questions without hitting limits

**Solution**: Dynamic prompt sizing + priority system + overflow handling

**Token Budget Tracking**:

```python
class TokenBudgetManager:
    def __init__(self, max_tokens_per_request=4000):
        self.max_prompt_tokens = max_tokens_per_request
        self.max_completion_tokens = 16000  # gpt-4 limit
        self.total_tokens_used = 0
        self.window_token_usage = []
        self.safety_buffer = 0.8  # Use 80% of max to be safe

    def check_budget_before_window(self, window_num, context_text, question_count):
        """
        Check if we have enough tokens for this window.
        Adjust prompt if needed.

        Returns:
            adjusted_context: str (possibly truncated)
            can_proceed: bool
        """
        # Estimate tokens for this window
        base_prompt_tokens = self._estimate_tokens(context_text)
        question_tokens = question_count * 50  # ~50 tokens per question
        estimated_completion = question_count * 150  # ~150 tokens per answer

        total_estimate = base_prompt_tokens + question_tokens + estimated_completion

        logger.info(f"Window {window_num} token estimate: {total_estimate}")
        logger.info(f"  - Context: {base_prompt_tokens}")
        logger.info(f"  - Questions: {question_tokens}")
        logger.info(f"  - Estimated completion: {estimated_completion}")

        # Check if within limits
        max_allowed = self.max_prompt_tokens * self.safety_buffer

        if base_prompt_tokens > max_allowed:
            # Context too long, need to truncate
            logger.warning(f"Context exceeds budget ({base_prompt_tokens} > {max_allowed})")
            adjusted_context = self._truncate_context(context_text, max_allowed)
            logger.info(f"Truncated context to {self._estimate_tokens(adjusted_context)} tokens")
            return adjusted_context, True

        return context_text, True

    def _estimate_tokens(self, text):
        """Estimate token count (rough: 4 chars â‰ˆ 1 token)."""
        return len(text) // 4

    def _truncate_context(self, text, max_tokens):
        """
        Intelligently truncate context to fit budget.
        Preserve beginning and end (most important sections).
        """
        target_chars = max_tokens * 4

        if len(text) <= target_chars:
            return text

        # Keep first 60% and last 40%
        keep_start = int(target_chars * 0.6)
        keep_end = int(target_chars * 0.4)

        truncated = text[:keep_start] + "\n\n[... middle section truncated ...]\n\n" + text[-keep_end:]

        return truncated

    def record_usage(self, window_num, prompt_tokens, completion_tokens):
        """Record actual token usage after API call."""
        total = prompt_tokens + completion_tokens
        self.total_tokens_used += total

        self.window_token_usage.append({
            'window': window_num,
            'prompt': prompt_tokens,
            'completion': completion_tokens,
            'total': total
        })

        logger.info(f"Window {window_num} actual tokens: {total} (prompt: {prompt_tokens}, completion: {completion_tokens})")
        logger.info(f"Total tokens used: {self.total_tokens_used}")

    def get_statistics(self):
        """Get token usage statistics."""
        if not self.window_token_usage:
            return {}

        total_prompt = sum(w['prompt'] for w in self.window_token_usage)
        total_completion = sum(w['completion'] for w in self.window_token_usage)
        avg_per_window = self.total_tokens_used / len(self.window_token_usage)

        return {
            'total_tokens': self.total_tokens_used,
            'total_prompt_tokens': total_prompt,
            'total_completion_tokens': total_completion,
            'windows_processed': len(self.window_token_usage),
            'avg_tokens_per_window': avg_per_window,
            'estimated_cost_usd': self.total_tokens_used * 0.00003  # Rough estimate
        }
```

**Priority System for Questions**:

If token budget is tight, prioritize unanswered questions:

```python
def prioritize_questions(all_questions, answered_so_far):
    """
    Prioritize questions to maximize coverage.

    Returns:
        priority_questions: List[Question] sorted by priority
    """
    unanswered = [q for q in all_questions if q.id not in answered_so_far]
    partially_answered = [q for q in all_questions if q.id in answered_so_far
                         and answered_so_far[q.id]['confidence'] < 0.7]
    well_answered = [q for q in all_questions if q.id in answered_so_far
                    and answered_so_far[q.id]['confidence'] >= 0.7]

    # Priority: unanswered > partially > well-answered
    return unanswered + partially_answered + well_answered
```

---

### LAYER 6: Output Compilation & Export

**Purpose**: Present results to user in browser and export formats

**Browser Display** (Unitary Log Table):

```html
<table class="unitary-log-table">
  <thead>
    <tr>
      <th>Question</th>
      <th>Answer</th>
      <th>Confidence</th>
      <th>Pages</th>
    </tr>
  </thead>
  <tbody>
    <tr data-question-id="Q1">
      <td>Q1. What is the project name?</td>
      <td>
        <span class="confidence-badge high">ğŸŸ¢ High</span>
        XYZ Sewer Rehabilitation Project
        <span class="pdf-citation"><PDF pg 1, 3, 5></span>
        <button class="show-variants">+2 more details</button>
      </td>
      <td>0.95</td>
      <td>1, 3, 5</td>
    </tr>
    <tr data-question-id="Q28">
      <td>Q28. What resin type is required?</td>
      <td>
        <span class="confidence-badge high">ğŸŸ¢ High</span>
        Vinyl ester resin per ASTM F1216 required
        <span class="pdf-citation"><PDF pg 3, 13, 14></span>
        <button class="show-variants">+2 more details</button>
      </td>
      <td>0.92</td>
      <td>3, 13, 14</td>
    </tr>
  </tbody>
</table>

<!-- Variants Modal (hidden by default) -->
<div id="variants-modal" class="modal">
  <div class="modal-content">
    <h3>All Answer Variants for Q28</h3>
    <div class="variant">
      <strong>Answer 1 (Primary):</strong>
      Vinyl ester resin per ASTM F1216 required <PDF pg 3, 13, 14>
      <br>Confidence: 0.92 | Pages: 3, 13, 14
    </div>
    <div class="variant">
      <strong>Answer 2:</strong>
      Resin shall cure at minimum 180Â°F <PDF pg 41>
      <br>Confidence: 0.85 | Pages: 41
    </div>
    <div class="variant">
      <strong>Answer 3:</strong>
      Minimum wall thickness after curing: 6mm <PDF pg 67>
      <br>Confidence: 0.88 | Pages: 67
    </div>
  </div>
</div>
```

**Excel Export Format**:

**Sheet 1: "Analysis Results"**

| Question | Primary Answer | Confidence | Pages | Expert | Variants |
|----------|---------------|------------|-------|--------|----------|
| Q1: Project name? | XYZ Sewer Rehabilitation Project <PDF pg 1, 3, 5> | High (0.95) | 1, 3, 5 | GeneralProjectExpert | 0 |
| Q28: Resin type? | Vinyl ester resin per ASTM F1216 <PDF pg 3, 13, 14> | High (0.92) | 3, 13, 14 | MaterialsSpecialist | 2 |

**Sheet 2: "All Answer Variants"**

| Question | Answer Variant | Confidence | Pages | Type |
|----------|----------------|------------|-------|------|
| Q28: Resin type? | Vinyl ester resin per ASTM F1216 <PDF pg 3, 13, 14> | 0.92 | 3, 13, 14 | material_specification |
| Q28: Resin type? | Resin shall cure at minimum 180Â°F <PDF pg 41> | 0.85 | 41 | curing_requirement |
| Q28: Resin type? | Minimum wall thickness: 6mm <PDF pg 67> | 0.88 | 67 | dimensional_requirement |

**Sheet 3: "Metadata & Statistics"**

| Metric | Value |
|--------|-------|
| Document Name | cipp_bid_2024.pdf |
| Total Pages | 120 |
| Pages Analyzed | 120 (100%) |
| Total Questions | 105 |
| Questions Answered | 105 (100%) |
| Average Confidence | 0.86 (High) |
| High Confidence Answers | 89 (84.8%) |
| Medium Confidence | 14 (13.3%) |
| Low Confidence | 2 (1.9%) |
| Total Tokens Used | 124,582 |
| Estimated API Cost | $3.74 |
| Processing Time | 6 min 32 sec |
| Expert Personas Used | 9 |

---

## Complete Data Flow Example

**User uploads**: 50-page CIPP bid specification PDF

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USER ACTION: Upload "cipp_bid_2024.pdf" (50 pages)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 0: Document Ingestion                                  â”‚
â”‚   â€¢ PyMuPDF extracts 50 pages with text                      â”‚
â”‚   â€¢ Output: [(1, text1), (2, text2), ..., (50, text50)]     â”‚
â”‚   â€¢ Metadata: {total_pages: 50, chars: 98,000}               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 1: Load Configuration                                  â”‚
â”‚   â€¢ Loads "CIPP Analysis v2.0" config                        â”‚
â”‚   â€¢ 9 sections, 105 questions                                â”‚
â”‚   â€¢ Section map created                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 2: Generate 9 Expert Personas                          â”‚
â”‚   FOR EACH SECTION:                                           â”‚
â”‚   â€¢ "General Info" â†’ GeneralProjectExpert (generated)        â”‚
â”‚   â€¢ "Materials" â†’ MaterialsSpecialist (generated)            â”‚
â”‚   â€¢ "Safety" â†’ SafetyComplianceOfficer (generated)           â”‚
â”‚   ... (all 9 generated via AI, cached for reuse)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LAYER 3-6: Process 17 Windows (50 pages Ã· 3)                â”‚
â”‚                                                               â”‚
â”‚ Window 1 (Pages 1-3):                                        â”‚
â”‚   L3: 9 experts process in parallel                          â”‚
â”‚   L4: Accumulate answers (first time, so just append)        â”‚
â”‚   L5: Token usage: 8,234 tokens                              â”‚
â”‚   L6: Display partial results in browser                     â”‚
â”‚                                                               â”‚
â”‚ Window 2 (Pages 4-6):                                        â”‚
â”‚   L3: 9 experts process                                      â”‚
â”‚   L4: Merge new answers with Window 1 results                â”‚
â”‚       â€¢ Q1: Similar to W1, merge pages [1,3] + [5] = [1,3,5]â”‚
â”‚       â€¢ Q28: New detail found, merge text + pages            â”‚
â”‚   L5: Token usage: 7,892 tokens (total: 16,126)             â”‚
â”‚   L6: Update browser display                                 â”‚
â”‚                                                               â”‚
â”‚ ... (Windows 3-16 process similarly)                        â”‚
â”‚                                                               â”‚
â”‚ Window 17 (Pages 49-50):                                     â”‚
â”‚   L3: Final expert processing                                â”‚
â”‚   L4: Final accumulation                                     â”‚
â”‚       â€¢ All 105 questions now have answers                   â”‚
â”‚       â€¢ Page citations aggregated across all windows         â”‚
â”‚   L5: Total tokens: 124,582                                  â”‚
â”‚   L6: Display complete unitary log                           â”‚
â”‚                                                               â”‚
â”‚ COMPLETION:                                                   â”‚
â”‚   â€¢ All 50 pages processed âœ…                                â”‚
â”‚   â€¢ All 105 questions answered âœ…                            â”‚
â”‚   â€¢ All PDF citations preserved âœ…                           â”‚
â”‚   â€¢ Export ready âœ…                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USER ACTION: Click "Export to Excel"                         â”‚
â”‚                                                               â”‚
â”‚   â€¢ Sheet 1: 105 primary answers with citations              â”‚
â”‚   â€¢ Sheet 2: All answer variants (if multiple)               â”‚
â”‚   â€¢ Sheet 3: Statistics and metadata                         â”‚
â”‚   â€¢ Downloaded: cipp_bid_2024_analysis.xlsx                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Implementation Priority

1. **Phase 1: Foundation** (Week 1-2)
   - âœ… Fix existing PDF page number bug FIRST
   - âœ… Implement Layer 0 (Document Ingestion) with validation
   - âœ… Implement Layer 1 (Configuration Loader) with JSON schema

2. **Phase 2: Dynamic Experts** (Week 2-3)
   - âœ… Implement Layer 2 (Expert Persona Generation)
   - âœ… Test expert generation with various section types
   - âœ… Build expert cache system

3. **Phase 3: Core Processing** (Week 3-5)
   - âœ… Implement Layer 3 (Multi-Expert Processing)
   - âœ… Parallel execution with asyncio
   - âœ… Page citation validation
   - âœ… Implement Layer 5 (Token Budget Manager)

4. **Phase 4: Smart Accumulation** (Week 5-6)
   - âœ… Implement Layer 4 (Deduplication)
   - âœ… Semantic similarity using embeddings
   - âœ… Information merging logic

5. **Phase 5: Output & Testing** (Week 6-7)
   - âœ… Implement Layer 6 (Compilation & Export)
   - âœ… Browser display with confidence badges
   - âœ… Excel export with all sheets
   - âœ… End-to-end testing with real PDFs

**Total Timeline: 7 weeks**
**Infrastructure: Flask + Redis (optional) = $7-17/mo**

---

## Success Metrics

**Critical Requirements** (Must Have):
- âœ… PDF page numbers display correctly in browser AND exports
- âœ… Zero information loss during deduplication
- âœ… 100% question coverage (all 105 questions answered)
- âœ… 100% page coverage (all pages processed)
- âœ… Token limits respected (no API errors)

**Performance Targets**:
- 50-page document: < 8 minutes total processing
- Parallel expert execution: 3-5 seconds per window
- Answer quality: â‰¥ 90% accuracy (expert validation)

**Flexibility Goals**:
- Support variable question counts (50-500+)
- Support custom section headings
- Support any document type (PDF, DOCX, TXT)

---

**HOTDOG AI is purpose-built for document analysis, not adapted from another architecture.**

Every layer serves the user's core need: **exhaustive, accurate, citation-perfect bid specification analysis with complete flexibility**.
